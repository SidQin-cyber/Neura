import { NextRequest, NextResponse } from 'next/server'
import { generateText } from 'ai'
import { openai } from '@ai-sdk/openai'

// ğŸ¯ æ–°çš„ Spark ç»“æœä¼˜åŒ– Prompt
const SPARK_OPTIMIZER_PROMPT = `ä½ æ˜¯ä¸€åé«˜çº§æ‹›è˜æœç´¢ç­–ç•¥å¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ç»“æ„åŒ–çš„å€™é€‰äººæˆ–èŒä½æ•°æ®ï¼Œè½¬æ¢ä¸ºä¸¤ç§ä¸ºæ··åˆæœç´¢ï¼ˆHybrid Searchï¼‰é‡èº«å®šåˆ¶çš„ä¼˜åŒ–æ–‡æœ¬ã€‚

**è¾“å…¥ï¼š** ä¸€ä¸ªåŒ…å«è§£æåæœç´¢æ¡ä»¶çš„ JSON å¯¹è±¡ã€‚

**è¾“å‡ºè¦æ±‚ï¼š** ç›´æ¥è¿”å›ä¸€ä¸ªåŒ…å«ä¸¤ä¸ªå­—æ®µçš„ JSON å¯¹è±¡ï¼Œä¸è¦ä½¿ç”¨ä»»ä½• markdown ä»£ç å—æ ‡è®°ï¼š
1. \`embeddingText\`: ä¸€æ®µæµç•…ã€è¯­ä¹‰ä¸°å¯Œçš„è‡ªç„¶è¯­è¨€æè¿°ã€‚è¿™æ®µæ–‡æœ¬å°†ç”¨äºç”Ÿæˆé«˜è´¨é‡çš„å‘é‡åµŒå…¥ï¼ˆEmbeddingï¼‰ã€‚å®ƒåº”è¯¥å®Œæ•´åœ°è¡¨è¾¾æœç´¢æ„å›¾ï¼Œçªå‡ºæ ¸å¿ƒè¦æ±‚å’Œå¸å¼•åŠ›ã€‚
2. \`ftsKeywords\`: ä¸€ä¸ªç”± 3-5 ä¸ªæœ€æ ¸å¿ƒã€æœ€ç›¸å…³çš„å…³é”®è¯ç»„æˆçš„å­—ç¬¦ä¸²ï¼Œç”¨ç©ºæ ¼åˆ†éš”ã€‚è¿™äº›å…³é”®è¯å°†ç”¨äºå…¨æ–‡æœç´¢ï¼ˆFTSï¼‰ï¼Œå¿…é¡»ç²¾ç‚¼ã€é«˜å‘½ä¸­ç‡ã€‚

---
**æ ¸å¿ƒåŸåˆ™ï¼š**

â€¢ **Embedding æ–‡æœ¬ï¼š** è¿½æ±‚"æ„å›¾å®Œæ•´"å’Œ"è¯­ä¹‰ä¸°å¯Œ"ã€‚å°†æ‰€æœ‰å…³é”®ä¿¡æ¯è‡ªç„¶åœ°ä¸²è”æˆä¸€å¥è¯ã€‚
â€¢ **FTS å…³é”®è¯ï¼š** è¿½æ±‚"é«˜ä¿¡å™ªæ¯”"å’Œ"é«˜åŒºåˆ†åº¦"ã€‚åªé€‰æ‹©æœ€ä¸å¯èƒ½è¢«è¯¯è§£çš„æ ¸å¿ƒè¯æ±‡ã€‚é¿å…ä½¿ç”¨å®½æ³›çš„è¯ï¼ˆå¦‚"å·¥ç¨‹å¸ˆ"ã€"è¦æ±‚"ï¼‰ã€‚

---
**ç¤ºä¾‹ï¼š**

è¾“å…¥ (å€™é€‰äººæœç´¢):
{
  "role": ["Goå·¥ç¨‹å¸ˆ"],
  "skills_must": ["Go", "Kubernetes"],
  "experience_min": 5,
  "location": ["åŒ—äº¬"]
}

è¾“å‡º:
{
  "embeddingText": "å¯»æ‰¾ä¸€åä½äºåŒ—äº¬ã€å…·å¤‡5å¹´ä»¥ä¸Šå·¥ä½œç»éªŒã€ç²¾é€šGoè¯­è¨€å’ŒKubernetesæŠ€æœ¯çš„åç«¯å·¥ç¨‹å¸ˆã€‚",
  "ftsKeywords": "Goå·¥ç¨‹å¸ˆ Kubernetes 5å¹´ åŒ—äº¬"
}

---

è¾“å…¥ (èŒä½æœç´¢):
{
  "role": ["äº§å“ç»ç†"],
  "skills_must": ["æ•°æ®åˆ†æ", "ç”¨æˆ·ç ”ç©¶"],
  "industry": ["äº’è”ç½‘"],
  "company": ["å¤§å‹ç§‘æŠ€å…¬å¸"]
}

è¾“å‡º:
{
  "embeddingText": "æ‹›è˜æ¥è‡ªå¤§å‹ç§‘æŠ€å…¬å¸ã€å…·å¤‡äº’è”ç½‘è¡Œä¸šèƒŒæ™¯ã€ç²¾é€šæ•°æ®åˆ†æå’Œç”¨æˆ·ç ”ç©¶çš„é«˜çº§äº§å“ç»ç†èŒä½ã€‚",
  "ftsKeywords": "äº§å“ç»ç† æ•°æ®åˆ†æ ç”¨æˆ·ç ”ç©¶ ç§‘æŠ€å…¬å¸"
}

è¯·ç›´æ¥è¿”å› JSON å¯¹è±¡ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæ–‡å­—æˆ–ä»£ç å—æ ‡è®°ã€‚`

export async function POST(request: NextRequest) {
  try {
    const { parsedData } = await request.json()

    if (!parsedData) {
      return NextResponse.json(
        { error: 'parsedData is required' },
        { status: 400 }
      )
    }

    console.log('ğŸš€ Spark ä¼˜åŒ–æµç¨‹å¯åŠ¨ï¼Œè¾“å…¥æ•°æ®:', parsedData)

    // è°ƒç”¨ LLM è¿›è¡Œæ™ºèƒ½ä¼˜åŒ–
    const { text } = await generateText({
      model: openai('gpt-4o-mini'),
      system: SPARK_OPTIMIZER_PROMPT,
      prompt: JSON.stringify(parsedData, null, 2),
      temperature: 0.2,
      maxTokens: 300
    })

    console.log('ğŸ¤– LLM ä¼˜åŒ–ç»“æœ:', text)

    // æ¸…ç† LLM è¿”å›çš„æ–‡æœ¬ï¼Œç§»é™¤å¯èƒ½çš„ markdown æ ‡è®°
    const cleanedText = text
      .replace(/```json\s*/g, '')  // ç§»é™¤å¼€å§‹çš„ ```json
      .replace(/```\s*$/g, '')     // ç§»é™¤ç»“å°¾çš„ ```
      .trim()

    console.log('ğŸ§¹ æ¸…ç†åçš„æ–‡æœ¬:', cleanedText)

    // è§£æ LLM è¿”å›çš„ JSON
    let optimizedResult: { embeddingText: string; ftsKeywords: string }
    try {
      optimizedResult = JSON.parse(cleanedText)
    } catch (e) {
      console.error('âŒ è§£æ LLM ä¼˜åŒ–ç»“æœå¤±è´¥:', e)
      // å¦‚æœè§£æå¤±è´¥ï¼Œæä¾›ä¸€ä¸ªåŸºäºè§„åˆ™çš„ã€æ›´å®‰å…¨çš„åå¤‡æ–¹æ¡ˆ
      const fallbackFts = parsedData.skills_must?.join(' ') || parsedData.role?.join(' ') || ''
      const fallbackEmbedding = parsedData.rewritten_query || JSON.stringify(parsedData)
      return NextResponse.json({
        success: false,
        error: 'Failed to parse optimizer response',
        embeddingText: fallbackEmbedding,
        ftsKeywords: fallbackFts,
        meta: {
          fallback_mode: true
        }
      })
    }

    console.log('âœ… ä¼˜åŒ–æˆåŠŸ:', {
      embeddingText: optimizedResult.embeddingText?.substring(0, 100) + '...',
      ftsKeywords: optimizedResult.ftsKeywords,
      optimization_model: 'gpt-4o-mini'
    })

    return NextResponse.json({
      success: true,
      embeddingText: optimizedResult.embeddingText,
      ftsKeywords: optimizedResult.ftsKeywords,
      meta: {
        optimization_model: 'gpt-4o-mini',
        embedding_length: optimizedResult.embeddingText?.length || 0,
        keyword_count: optimizedResult.ftsKeywords?.split(' ').length || 0
      }
    })

  } catch (error) {
    console.error('âŒ Spark æ ¼å¼åŒ–å¤±è´¥:', error)
    return NextResponse.json(
      {
        error: 'Internal server error',
        details: error instanceof Error ? error.message : 'Unknown error'
      },
      { status: 500 }
    )
  }
}